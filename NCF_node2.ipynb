{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "from sklearn.utils import shuffle\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "from itertools import product\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. 데이터 생성 및 전처리 과정"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1-1 기존 데이터 (user_course에 학과, 과목 삭제 조건 적용)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data initialization\n",
    "user_major = {}\n",
    "category_course = {}\n",
    "major_category = pd.read_csv('./data/major_category.csv', encoding='CP949', header=None)\n",
    "major_course={}\n",
    "userlist=[]\n",
    "courselist=[]\n",
    "elelist=[]\n",
    "ele_course=[]\n",
    "\n",
    "# hakno re\n",
    "coursere=re.compile('^[A-Z]{3}\\d*')\n",
    "\n",
    "# category, deluniv input\n",
    "with open('./data/catlist.txt', encoding='UTF-8') as f:\n",
    "    valid_category = [cate.split(\"\\t\")[0] for cate in f.readlines()]\n",
    "with open('./data/elelist.txt', encoding='UTF-8') as f:\n",
    "    elelist = [cate.split(\"\\t\")[0] for cate in f.readlines()]\n",
    "with open('./data/deluniv.txt', encoding='UTF-8') as f:\n",
    "    deluniv = [univ[:-1] for univ in f.readlines()]\n",
    "    \n",
    "# data creation\n",
    "user_course = pd.read_csv('./data/course_userdata.csv', low_memory=False, header=None)\n",
    "for row in user_course.values:\n",
    "    if (row[1] in deluniv or str(row[4]) not in valid_category or re.match(coursere, row[5]) == None):\n",
    "        continue\n",
    "    user = row[0]\n",
    "    major = row[1] + '_' + row[2]\n",
    "    category = row[4]\n",
    "    course = re.search(coursere, row[5]).group()\n",
    "    year = row[6]\n",
    "    term = row[7]\n",
    "    if user not in user_major:\n",
    "        user_major[user] = [major]\n",
    "        userlist.append(user)\n",
    "    elif major not in user_major[user]:\n",
    "        user_major[user].append(major)\n",
    "\n",
    "    if category not in category_course:\n",
    "        category_course[category] = [course]\n",
    "    elif course not in category_course[category]:\n",
    "        category_course[category].append(course)\n",
    "\n",
    "    if (category in elelist and course not in ele_course):\n",
    "        ele_course.append(course)\n",
    "\n",
    "    if course not in courselist:\n",
    "        courselist.append(course)\n",
    "\n",
    "for row in major_category.values:\n",
    "    if row[0] not in major_course:\n",
    "        major_course[row[0]] = category_course[row[1]]\n",
    "    else:\n",
    "        major_course[row[0]] += category_course[row[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(len(user_course))\n",
    "user_course.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1-2 학습을 위한 추가 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 수정을 위해 컬럼명 지정\n",
    "user_course.columns = ['a','b','c','d','e','f','g','h','i']\n",
    "\n",
    "#a:삭제 대상 학과, b:고려대상 과목, c:조건에 해당하는 user, d:15,16,17년도 각각 조건 적용\n",
    "a = ~user_course.b.isin(deluniv)\n",
    "b = user_course.f.str.contains(coursere)\n",
    "c = user_course.a.isin(userlist)\n",
    "d = user_course.g.isin([2015,2016,2017])\n",
    "user_course = user_course[a & b & c & d]\n",
    "\n",
    "#j 컬럼에 학정번호 앞부분 저장(분반제거) ex) CEE4402-01 > CEE4402\n",
    "user_course['j'] = user_course['f'].str.findall(coursere)\n",
    "user_course['j'] = user_course.f.str.split('-').str[0]\n",
    "user_course = user_course[user_course['j'].isin(courselist)]\n",
    "\n",
    "#17-2에 수업 들었던 학생(user_20172), 15,16,17-1에 수업 들었던 학생(user_left)\n",
    "#17년 2월에 수업 들었던 학생 중 나머지 학기에도 들었던 학생(user_fit)리스트 저장\n",
    "user_20172 = list(set(user_course[(user_course['g'] == 2017) & (user_course['h'] == 2)]['a'].tolist()))\n",
    "user_left = list(set(user_course[~((user_course['g'] == 2017) & (user_course['h'] == 2))]['a'].tolist()))\n",
    "user_fit = []\n",
    "for i in user_20172:\n",
    "    if i in user_left:\n",
    "        user_fit.append(i)\n",
    "\n",
    "#user_fit에 해당하는 학생들의 데이터만 남겨서 user_course에 filtering\n",
    "user_course = user_course[user_course.a.isin(user_fit)]\n",
    "        \n",
    "#2017년 2학기 개강한 수업(course_20172_list)\n",
    "course_20172_list = list(set(user_course[(user_course['g'] == 2017) & (user_course['h'] == 2)]['j'].tolist()))\n",
    "\n",
    "print(\"17-2에 수업 들었던 학생 : {}\".format(len(user_20172)))\n",
    "print(\"15,16,17-1에 수업 들었던 학생 : {}\".format(len(user_left)))\n",
    "print(\"17년 2월에 수업 들었던 학생 중 나머지 학기에도 들었던 학생 : {}\".format(len(user_fit)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# user_course (1920266 > 285482)\n",
    "print(len(user_course))\n",
    "user_course.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. NCF 학습"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2-1 학습 데이터 생성"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "user_course['user_id'] = user_course['a'].astype(\"category\").cat.codes\n",
    "user_course['item_id'] = user_course['j'].astype(\"category\").cat.codes\n",
    "df_to_node2vec = user_course[['a','b','c','d','j','i','g','h','user_id','item_id']].copy()\n",
    "df_to_node2vec.columns = ['user', 'major1', 'major2', 'item_name', 'item_num', 'item_major', 'year', 'semester', 'user_id', 'item_id']\n",
    "df_to_node2vec = df_to_node2vec.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 데이터 전달\n",
    "df_to_node2vec.to_csv('./data/df_to_node2vec.csv',encoding=\"CP949\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_course_inter_df = user_course[['a','j','g','h']].copy()\n",
    "user_course_inter_df.columns = ['user','item','year','sem']\n",
    "user_course_inter_df = user_course_inter_df.reset_index(drop=True)\n",
    "\n",
    "user_course_train = user_course_inter_df[~((user_course_inter_df['year'] == 2017) & (user_course_inter_df['sem'] == 2))].copy()\n",
    "user_course_test = user_course_inter_df[(user_course_inter_df['year'] == 2017) & (user_course_inter_df['sem'] == 2)].copy()\n",
    "\n",
    "# item_id 부여 + user_id column 추가\n",
    "user_course_train['user_id'] = user_course_train['user'].astype(\"category\").cat.codes\n",
    "user_course_train['item_id'] = user_course_train['item'].astype(\"category\").cat.codes\n",
    "\n",
    "users = list(np.sort(user_course_train.user_id.unique()))\n",
    "items = list(np.sort(user_course_train.item_id.unique()))\n",
    "\n",
    "print(\"# of train users : {}\".format(len(users)))\n",
    "print(\"# of train items : {}\".format(len(items)))\n",
    "print(\"# of interactions : {}\".format(len(user_course_inter_df)))\n",
    "\n",
    "print(\"train inter : {}\".format(len(user_course_train)))\n",
    "print(\"test inter : {}\".format(len(user_course_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_dict = dict(zip(user_course_train['user_id'].tolist(), user_course_train['user'].tolist()))\n",
    "item_dict = dict(zip(user_course_train['item_id'].tolist(), user_course_train['item'].tolist()))\n",
    "item_dict_T = dict(zip(user_course_train['item'].tolist(), user_course_train['item_id'].tolist()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2-2 negative case 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "neg_num=4\n",
    "neg_full_u = []\n",
    "neg_full_i = []\n",
    "\n",
    "for u in tqdm(users):\n",
    "    train_num = len(user_course_train[user_course_train['user_id']==u])\n",
    "    full = {i for i in range(len(items))}\n",
    "    asis = set(user_course_train[user_course_train['user_id']==u]['item_id'].tolist())\n",
    "    \n",
    "    temp_neg_u = [u for i in range(train_num*neg_num)]\n",
    "    temp_neg_i = random.sample(list(full-asis), train_num*neg_num)\n",
    "    \n",
    "    neg_full_u.extend(temp_neg_u)\n",
    "    neg_full_i.extend(temp_neg_i)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2-3 train_df 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u_df = user_course_train['user_id'].tolist()\n",
    "u_df.extend(neg_full_u)\n",
    "\n",
    "i_df = user_course_train['item_id'].tolist()\n",
    "i_df.extend(neg_full_i)\n",
    "\n",
    "p_df = [1 for i in range(len(user_course_train))]\n",
    "p_df.extend([0 for i in range(len(neg_full_u))])\n",
    "\n",
    "print(len(u_df),len(i_df),len(p_df))\n",
    "\n",
    "train_df = pd.DataFrame({'user_id':u_df, 'item_id':i_df, 'plays':p_df})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 인풋 생성 + shuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train user, item 리스트 생성\n",
    "rows = train_df['user_id'].astype(int)\n",
    "cols = train_df['item_id'].astype(int)\n",
    "values = list(train_df.plays)\n",
    "\n",
    "uids = np.array(rows.tolist())\n",
    "iids = np.array(cols.tolist())\n",
    "\n",
    "user_input = uids.tolist()\n",
    "item_input = iids.tolist()\n",
    "labels = values\n",
    "\n",
    "user_data_shuff, item_data_shuff, label_data_shuff = shuffle(user_input, item_input, labels)\n",
    "user_data_shuff = np.array(user_data_shuff).reshape(-1,1)\n",
    "item_data_shuff = np.array(item_data_shuff).reshape(-1,1)\n",
    "label_data_shuff = np.array(label_data_shuff).reshape(-1,1)\n",
    "\n",
    "print(len(user_data_shuff))\n",
    "print(len(item_data_shuff))\n",
    "print(len(label_data_shuff))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_course_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Node2Vec embedding 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# node2vec.wv.vectors.shape\n",
    "# node2vec.wv.vectors\n",
    "# node2vec.wv.index2entity\n",
    "\n",
    "emb_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data/student_emb'+str(emb_size)+'.pickle', 'rb') as f:\n",
    "    node2vec_u = pickle.load(f)\n",
    "print(node2vec_u.vectors.shape)\n",
    "\n",
    "node2vec_u_sort = []\n",
    "\n",
    "for i in tqdm(range(len(users))):\n",
    "    idx=node2vec_u.index2entity.index(str(user_dict[i]))\n",
    "    node2vec_u_sort.append(list(node2vec_u.vectors[idx]))\n",
    "\n",
    "node2vec_u_sort = np.array(node2vec_u_sort,dtype=np.float32)\n",
    "node2vec_u_sort.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data/course_emb'+str(emb_size)+'.pickle', 'rb') as f:\n",
    "    node2vec = pickle.load(f)\n",
    "print(node2vec.wv.vectors.shape)\n",
    "\n",
    "node2vec_sort = []\n",
    "\n",
    "for i in tqdm(range(len(items))):\n",
    "    idx=node2vec.wv.index2entity.index(item_dict[i])\n",
    "    node2vec_sort.append(list(node2vec.wv.vectors[idx]))\n",
    "\n",
    "node2vec_sort = np.array(node2vec_sort,dtype=np.float32)\n",
    "node2vec_sort.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.NeuMF_node import NeuMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nmf = NeuMF(len(users), len(items), emb_size,node2vec_u_sort ,node2vec_sort)\n",
    "model=nmf.get_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model.fit([user_data_shuff, item_data_shuff], label_data_shuff, epochs=20,\n",
    "               batch_size=256, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save('./pretrain/ncf'+str(emb_size)+'-node2.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_return(u, K):\n",
    "    user=user_course_train[user_course_train['user_id']==u]['user'].iloc[0]\n",
    "    \n",
    "    full = set([i for i in range(len(items))])\n",
    "    asis = set(user_course_train[user_course_train['user_id']==u]['item_id'].tolist())\n",
    "    pred_cand_list = list(full-asis)\n",
    "    pred_user_list = [u for i in range(len(pred_cand_list))]\n",
    "    \n",
    "    pred_user = np.array(pred_user_list).reshape(-1,1)\n",
    "    pred_cand = np.array(pred_cand_list).reshape(-1,1)\n",
    "    \n",
    "    # predict 진행\n",
    "    predictions = model.predict([pred_user, pred_cand])\n",
    "    predictions = predictions.flatten().tolist()\n",
    "\n",
    "    # (full) predict한 item 이름으로 변겅해서 저장\n",
    "    pred_cand_list_name = list(map(lambda x:item_dict[x], pred_cand_list)) \n",
    "    \n",
    "    pred_df = pd.DataFrame({'item_id':pred_cand_list,'item':pred_cand_list_name, 'score':predictions})\n",
    "    \n",
    "    # (in) 유저의 전공과목에 해당되는지\n",
    "    temp_user_major = major_course[user_major[user][0]]\n",
    "    pred_cand_list_name = [x for x in pred_cand_list_name if x in temp_user_major]\n",
    "    \n",
    "    # (in) test 데이터 안에 있는 과목인지 (2017-2 개설과목 조건)\n",
    "    temp_test_full_course = list(set(user_course_test['item']))\n",
    "    pred_cand_list_name = [x for x in pred_cand_list_name if x in temp_test_full_course]\n",
    "    \n",
    "    # 최종 output 생성\n",
    "    req_df = pred_df[pred_df['item'].isin(pred_cand_list_name)]\n",
    "    \n",
    "    req_list = req_df.sort_values(by='score',ascending=False)['item'].tolist()\n",
    "    \n",
    "    return(req_list[0:K], user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_return(1,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test case load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def asis_return(u):\n",
    "    user=user_course_train[user_course_train['user_id']==u]['user'].iloc[0]\n",
    "\n",
    "    # 유저에 해당되는 전공 과목 리스트 가져옴\n",
    "    temp_user_major = major_course[user_major[user][0]]\n",
    "\n",
    "    temp_asis_df = user_course_test[user_course_test['user']==user].copy()\n",
    "\n",
    "    req_asis = temp_asis_df[temp_asis_df['item'].isin(temp_user_major)]\n",
    "\n",
    "    return(req_asis['item'].tolist(), user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# user_id 만 집어넣음\n",
    "asis_return(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def recall_(p,r):\n",
    "    try:\n",
    "        return(int(sum(p))/int(len(r)))\n",
    "    except:\n",
    "        return(0)\n",
    "\n",
    "def precision_at_k(r, k):\n",
    "    assert k >= 1\n",
    "    r = np.asarray(r)[:k] != 0\n",
    "    #print(r)\n",
    "    if r.size != k:\n",
    "        raise ValueError('Relevance score length < k')\n",
    "    return np.mean(r)\n",
    "\n",
    "\n",
    "def average_precision(r):\n",
    "    r = np.asarray(r) != 0\n",
    "    out = [precision_at_k(r, k + 1) for k in range(r.size) if r[k]]\n",
    "    if not out:\n",
    "        return 0.\n",
    "    return np.mean(out)\n",
    "\n",
    "\n",
    "def mean_average_precision(rs):\n",
    "    return np.mean([average_precision(r) for r in rs])\n",
    "\n",
    "def dcg_at_k(r, k, method=0):\n",
    "    r = np.asfarray(r)[:k]\n",
    "    if r.size:\n",
    "        if method == 0:\n",
    "            return r[0] + np.sum(r[1:] / np.log2(np.arange(2, r.size + 1)))\n",
    "        elif method == 1:\n",
    "            return np.sum(r / np.log2(np.arange(2, r.size + 2)))\n",
    "        else:\n",
    "            raise ValueError('method must be 0 or 1.')\n",
    "    return 0.\n",
    "\n",
    "def ndcg_at_k(r, k=20, method=1):\n",
    "    dcg_max = dcg_at_k(sorted(r, reverse=True), k, method)\n",
    "    if not dcg_max:\n",
    "        return 0.\n",
    "    return dcg_at_k(r, k, method) / dcg_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p=[] #precision\n",
    "r=[] #recall\n",
    "m=[] #map\n",
    "n=[] #ndcg\n",
    "correct_list=[]\n",
    "K=10\n",
    "\n",
    "for i in tqdm(range(12031)):\n",
    "    eval_gt = asis_return(i)\n",
    "    eval_pred = predict_return(i,K) # pred개수\n",
    "\n",
    "    temp_req=[1 if c in eval_gt[0] else 0 for c in eval_pred[0]]\n",
    "    \n",
    "    correct_list.append(temp_req)\n",
    "    \n",
    "    if eval_gt[0] != []:\n",
    "        p.append(precision_at_k(temp_req,len(temp_req)))\n",
    "        r.append(recall_(temp_req, eval_gt[0]))\n",
    "        m.append(mean_average_precision([temp_req]))\n",
    "        n.append(ndcg_at_k(temp_req,len(temp_req)))\n",
    "        \n",
    "print(\"{:.4f} : Precision\".format(sum(p)/len(p)))\n",
    "print(\"{:.4f} : Recall\".format(sum(r)/len(r)))\n",
    "print(\"{:.4f} : MAP\".format(sum(m)/len(m)))\n",
    "print(\"{:.4f} : NDCG\".format(sum(n)/len(n)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_keras",
   "language": "python",
   "name": "tf_keras"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
